# -*- coding: utf-8 -*-
"""Markov_Chain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ydySgFpLlz26_b7xh1MR1MQCjnLLttx
"""

import pandas as pd
import numpy as np
import nltk
nltk.download('punkt')
import matplotlib.pyplot as plt
import scipy.linalg as la
import random

"""# Markov Chain Class Below!"""

# Class Markov Chain

class Markov_Chain(object):

  # Constructor
  def __init__(self, file_name, order, use_letters=False):
    self.file_name = file_name
    self.load_data(file_name)
    self.get_vocab(file_name)
    self.get_start_word_dist()
    # order represents the number of words used
    # to predict the next word in a generated sentence
    # and in this version the order is assumed to be 1
    self.order = order
    self.generate_frequency_table()
    self.generate_Markov_matrix()
    # self.add_dust()
    self.visualize_frequencies(num_common_words=10)
    self.compute_Perron_Frobenius()
    self.generate_text(3)

    print(self.last_words)

  # Function  
  def load_data(self, file_name):
    self.data = pd.read_csv(file_name, header=None)
  
  def get_vocab(self, file_name):
    words = open(file_name, encoding='utf8').read()
    self.word_list = words.split()
    vocab = []
    for word in self.word_list:
      if word not in vocab:
        vocab.append(word)
    self.vocab = vocab
  
  def view_data(self):
    print(self.data.head(5))
  
  def get_start_word_dist(self):
    self.first_words = []
    self.last_words = []
    self.first_word_prob = []
    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')
    fp = open(self.file_name)
    # fp = open("dr-seuss.txt")
    data = fp.read()
    # print('\n-----\n'.join(tokenizer.tokenize(data)))
    sentences = tokenizer.tokenize(data)
    # print(len(a))
    for i in range(len(sentences)):
      first_word = sentences[i].split()[0]
      last_word = sentences[i].split()[len(sentences[i].split()) - 1]
      if first_word not in self.first_words:
        self.first_words.append(first_word)
        self.first_word_prob.append(1)
      else:
        index = self.first_words.index(first_word)
        self.first_word_prob[index] += 1
        # self.last_words
      
      if last_word not in self.last_words:
        self.last_words.append(last_word)
      # print(first_word)
    self.first_word_prob = np.array(self.first_word_prob)
    self.first_word_prob = self.first_word_prob/self.first_word_prob.sum()
  
  def generate_frequency_table(self):
    # go through each word in text
    # if word not in df.columns
    # create a new column whose name is the word
    # create a new row whose first entry is the word
    freq_table = pd.DataFrame(columns=self.vocab)

    freq_table.loc[self.word_list[0], :] = [0] * len(self.vocab)
    freq_table.loc[self.word_list[0], self.word_list[len(self.word_list)-1]] += 1

    for i in range(len(self.word_list)-1):
      # print(self.word_list[i])
      if self.word_list[i+1] not in freq_table.index:
        freq_table.loc[self.word_list[i+1], :] = [0] * len(self.vocab)
      freq_table.loc[self.word_list[i+1], self.word_list[i]] += 1

    self.freq_table = freq_table
    print(freq_table.head(3))
    
  def generate_Markov_matrix(self):
    self.Markov_matrix = self.freq_table.copy()
    for column in self.Markov_matrix.columns:
      self.Markov_matrix[column] = self.Markov_matrix[column].div(self.Markov_matrix[column].sum())
    
    # matrix is generated
    round_matrix = self.Markov_matrix
    round_matrix = round_matrix.to_numpy()
    round_float = np.vstack(round_matrix[:, :]).astype(np.float)
    round_float = np.round(round_float, decimals=3)
    self.round_float = round_float
    self.round_float = pd.DataFrame(self.round_float, columns = self.vocab, index = self.vocab)

  def generate_text(self, num_sentences):
    # Randomly choose from a word in the probability distribution.
    # Use the Markov matrix to generate next word in chain
    for i in range(num_sentences):
      sentence = []
      # first_word = np.random.choice(np.arange(0, len(self.first_word_prob)), p=self.first_word_prob)
      first_word = random.choices(self.first_words, weights=self.first_word_prob, k=1)[0]
      next_word = first_word
      sentence.append(next_word)
      # if (first_word in self.last_words):
      #  print('First word in self.last_words')
      while (next_word not in self.last_words):
        # Choose next word from probability distribution of transitions 
        # from next_word column in Markov matrix
        next_word_prob_distr = self.Markov_matrix[next_word]
        next_word = random.choices(self.vocab, weights=next_word_prob_distr, k=1)[0]
        sentence.append(next_word)

        # next_word = np.random.choice(np.arange(0, len(next_word_prob_distr)), p=self.first_word_prob)
      for j in range(len(sentence)):
        if j != len(sentence) - 1:
          print(sentence[j], end = ' ')
        else:
          print(sentence[j], end = '\n')
      # print("\n")
    
  def visualize_frequencies(self, num_common_words):
    # do visualization on self.data
    frequencies = {}
    for word in self.word_list:
      if word not in frequencies:
        frequencies[word] = 0
      else:
        frequencies[word] += 1
    self.frequencies = frequencies

    # make a copy of frequencies that we can change
    freq_copy = frequencies
    most_common_words = {}

    # iterate through every key in dictionary to find most common words
    for i in range(0, num_common_words):
      max_key = max(freq_copy, key=freq_copy.get)
      most_common_words[max_key] = freq_copy[max_key]
      del freq_copy[max_key]
    
    print(str(num_common_words) + " Most Common Words: ")
    print(most_common_words)

    # plot most common words
    plt.bar(range(len(most_common_words)), list(most_common_words.values()), align='center')
    plt.xticks(range(len(most_common_words)), list(most_common_words.keys()))
    plt.title(label=str(num_common_words) + " Most Common Words: ")
    plt.show()
  
  def compute_Perron_Frobenius(self, plot_equilibrium=False, plot_convergence=False):
    '''
    # OPTION 1: COMPUTE EIGENVECTORS
    # assumes that this matrix is regular (can apply Perron-Frobenius)
    matrix = self.Markov_matrix
    matrix = matrix.to_numpy()
    matrix_float = np.vstack(matrix[:, :]).astype(np.float)
    # compute eigenvectors and eigenvalues of matrix
    eigvals, eigvecs = la.eig(matrix_float)
    print("eigvals: ")
    print(eigvals.real)
    print("eigenvecs: ")
    print(eigvecs.real)
    # there should be 1 eigenvector corresponding to the distinct 1-eigenvalue
    # this vector is the equilibrium vector u
    eq_vector = eigvecs.real[0]
    normalized_eq_vector = eq_vector / eq_vector.sum()
    print("equilibrium vector:")
    print(eq_vector)
    print("normalized equilibrium vector aka convergence vector:")
    print(normalized_eq_vector)
    print(f'sum of normalized_eq_vector components: {normalized_eq_vector.sum}')
    '''

    # OPTION 2: RAISE MATRIX TO A HIGH POWER
    matrix = self.Markov_matrix.copy()
    new_matrix = matrix
    for i in range(1, 21):
      new_matrix *= matrix
    print("PERRON-FROBENIUS MATRIX:")
    print(new_matrix)

  def add_dust(self):
    # go through each columm
    # find column sum
    # find d = 1 - column sum
    # add d to last element in each column
    # if d is negative, search through column
    # and add d to the first cell that is > -d
    for column in self.Markov_matrix.columns:
      column_distr = self.Markov_matrix[column] 
      diff = 1 - self.Markov_matrix[column].sum()
      # print(diff)
      # print()
      if diff < 0:
        for i in range(len(column_distr)):
          if column_distr[i] > -1 * diff:
            column_distr[i] = column_distr[i] + diff
            break
      else:
        column_distr[0] = column_distr[0] + diff
      self.Markov_matrix[column] = column_distr
      # print(f'column_distr.sum: {column_distr.sum()}')
      if column_distr.sum() != 1:
        print(f'column_distr.sum: {column_distr.sum()}')
      
  
  def generate_images(self, sentence):
    # Use DALLE's AI to generate images for each generated sentence.
    pass
  
  def create_Markov_graph(self, k_most_common_words):
    # Construct a graph with the k most common words and their
    # associated transitions to other words in the Markov matrix.
    pass

# download the dr-seuss.txt for this to work!
dr_seuss = Markov_Chain("dr-seuss.txt", 1)
# dr_seuss.view_data()

print(len(dr_seuss.vocab))

print(dr_seuss.Markov_matrix)

for column in dr_seuss.Markov_matrix.columns:
  # dr_seuss.Markov_matrix[column] = dr_seuss.Markov_matrix[column].round(3)
  if dr_seuss.Markov_matrix[column].sum() != 1:
    print('column sum != 1')
    print(dr_seuss.Markov_matrix[column].sum())

dr_seuss.generate_text(1)

